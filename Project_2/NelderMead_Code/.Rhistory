X1 ~~ X2+X3+X4+X5+X6+X7+X8+X9+X10
X2 ~~ X3+X4+X5+X6+X7+X8+X9+X10
X3 ~~ X4+X5+X6+X7+X8+X9+X10
X4 ~~ X5+X6+X7+X8+X9+X10
X5 ~~ X6+X7+X8+X9+X10
X6 ~~ X7+X8+X9+X10
X7 ~~ X8+X9+X10
X8 ~~ X9+X10
X9 ~~ X10
# intercepts
X1+X2+X3+X4+X5+X6+X7+X8+X9+X10+Y1+Y2+Y3+Y4+Y5+Y6+Y7+Y8+Y9+Y10~1
'
sem(model = myModel, data = SEMdata, int.ov)
set.seed(1)
n <- 1000
d <- 10 ## dimension of Y
p <- 10 ## dimension of X
k_Sig <- 2  ## number of factors for Y
xk_Sig <- 3 ## number of factors for X
bk <- 2.5*matrix(runif( p*(xk_Sig+1)), nrow = p, ncol = (xk_Sig+1)) ## b_k q x m+1
W <- matrix(rnorm(n*xk_Sig, mean = 0, sd = 1), nrow = xk_Sig) ## latent factor matrix W N(0,I) s x n
xlin.term  <- bk %*% rbind(rep(1, ncol(W)),W)
xlin.term <- t(xlin.term)
probsx <- 1/(1 + exp(-xlin.term))
xx <- matrix(0, nrow = n, ncol = p)
for (jj in 1: (ncol(xx)) ){
xx[, jj] <- rbinom(n, size = 1, prob = probsx[,jj]) ## generate X matrix n x q
}
colnames(xx) <- paste0('X', 1:(ncol(xx)))
ak <- 2.5*matrix(runif( d*(k_Sig+1)), nrow = d, ncol = (k_Sig+1)) ## a_k p x s+1
## make clean Lam0
ak[1:6, 1] <- 0
ak[7:d , 2] <- 0
Z <- matrix(0, nrow = k_Sig, ncol = n)
gamma <- matrix(runif(k_Sig*xk_Sig), nrow = k_Sig, ncol = xk_Sig) ## generate Gamma m x s
U <- matrix(rnorm(n*k_Sig, mean = 0, sd = 1), nrow = k_Sig, n) ## generate matrix U N(0,I) m x n
normal.factor = sqrt(sum(gamma^2))
lambda = matrix(0, nrow = k_Sig, ncol = k_Sig)
for(i in 1:k_Sig){
lambda[i,i] = sqrt(1 - sqrt(sum(gamma[i,]^2))/(normal.factor)) ## generate Lambda m x m
}
Z = gamma%*%W + lambda%*%U ## generate latent matrix Z m x n
ylin.term  <-  ak %*% rbind(rep(1, ncol(Z)),Z)
ylin.term <- t(ylin.term)
probsy <- 1/(1 + exp(-ylin.term))
yy <- matrix(0, nrow = n, ncol = d)
for (jj in 1: (ncol(yy)) ){
yy[, jj] <- rbinom(n, size = 1, prob = probsy[,jj]) ## generate Y matrix n x p
}
colnames(yy) <- paste0('Y', 1:(ncol(yy)))
library(lavaan)
SEMdata = cbind(xx,yy)
myModel <- '
# latent variables
WL1+WL2+WL3 =~ X1+X2+X3+X4+X5+X6+X7+X8+X9+X10
ZL1+ZL2 =~ Y1+Y2+Y3+Y4+Y5+Y6+Y7+Y8+Y9+Y10
# regressions
ZL1+ZL2 ~ WL1+WL2+WL3
# residual covariances
Y1 ~~ Y2+Y3+Y4+Y5+Y6+Y7+Y8+Y9+Y10
Y2 ~~ Y3+Y4+Y5+Y6+Y7+Y8+Y9+Y10
Y3 ~~ Y4+Y5+Y6+Y7+Y8+Y9+Y10
Y4 ~~ Y5+Y6+Y7+Y8+Y9+Y10
Y5 ~~ Y6+Y7+Y8+Y9+Y10
Y6 ~~ Y7+Y8+Y9+Y10
Y7 ~~ Y8+Y9+Y10
Y8 ~~ Y9+Y10
Y9 ~~ Y10
X1 ~~ X2+X3+X4+X5+X6+X7+X8+X9+X10
X2 ~~ X3+X4+X5+X6+X7+X8+X9+X10
X3 ~~ X4+X5+X6+X7+X8+X9+X10
X4 ~~ X5+X6+X7+X8+X9+X10
X5 ~~ X6+X7+X8+X9+X10
X6 ~~ X7+X8+X9+X10
X7 ~~ X8+X9+X10
X8 ~~ X9+X10
X9 ~~ X10
# intercepts
X1+X2+X3+X4+X5+X6+X7+X8+X9+X10+Y1+Y2+Y3+Y4+Y5+Y6+Y7+Y8+Y9+Y10~1
'
sem(model = myModel, data = SEMdata)
set.seed(1)
n <- 1000
d <- 10 ## dimension of Y
p <- 10 ## dimension of X
k_Sig <- 2  ## number of factors for Y
xk_Sig <- 3 ## number of factors for X
bk <- 2.5*matrix(runif( p*(xk_Sig+1)), nrow = p, ncol = (xk_Sig+1)) ## b_k q x m+1
W <- matrix(rnorm(n*xk_Sig, mean = 0, sd = 1), nrow = xk_Sig) ## latent factor matrix W N(0,I) s x n
xlin.term  <- bk %*% rbind(rep(1, ncol(W)),W)
xlin.term <- t(xlin.term)
probsx <- 1/(1 + exp(-xlin.term))
xx <- matrix(0, nrow = n, ncol = p)
for (jj in 1: (ncol(xx)) ){
xx[, jj] <- rbinom(n, size = 1, prob = probsx[,jj]) ## generate X matrix n x q
}
colnames(xx) <- paste0('X', 1:(ncol(xx)))
ak <- 2.5*matrix(runif( d*(k_Sig+1)), nrow = d, ncol = (k_Sig+1)) ## a_k p x s+1
## make clean Lam0
ak[1:6, 1] <- 0
ak[7:d , 2] <- 0
Z <- matrix(0, nrow = k_Sig, ncol = n)
gamma <- matrix(runif(k_Sig*xk_Sig), nrow = k_Sig, ncol = xk_Sig) ## generate Gamma m x s
U <- matrix(rnorm(n*k_Sig, mean = 0, sd = 1), nrow = k_Sig, n) ## generate matrix U N(0,I) m x n
normal.factor = sqrt(sum(gamma^2))
lambda = matrix(0, nrow = k_Sig, ncol = k_Sig)
for(i in 1:k_Sig){
lambda[i,i] = sqrt(1 - sqrt(sum(gamma[i,]^2))/(normal.factor)) ## generate Lambda m x m
}
Z = gamma%*%W + lambda%*%U ## generate latent matrix Z m x n
ylin.term  <-  ak %*% rbind(rep(1, ncol(Z)),Z)
ylin.term <- t(ylin.term)
probsy <- 1/(1 + exp(-ylin.term))
yy <- matrix(0, nrow = n, ncol = d)
for (jj in 1: (ncol(yy)) ){
yy[, jj] <- rbinom(n, size = 1, prob = probsy[,jj]) ## generate Y matrix n x p
}
colnames(yy) <- paste0('Y', 1:(ncol(yy)))
library(lavaan)
SEMdata = cbind(xx,yy)
myModel <- '
# latent variables
WL1+WL2+WL3 =~ X1+X2+X3+X4+X5+X6+X7+X8+X9+X10
ZL1+ZL2 =~ Y1+Y2+Y3+Y4+Y5+Y6+Y7+Y8+Y9+Y10
# regressions
ZL1+ZL2 ~ WL1+WL2+WL3
# residual covariances
Y1 ~~ Y2+Y3+Y4+Y5+Y6+Y7+Y8+Y9+Y10
Y2 ~~ Y3+Y4+Y5+Y6+Y7+Y8+Y9+Y10
Y3 ~~ Y4+Y5+Y6+Y7+Y8+Y9+Y10
Y4 ~~ Y5+Y6+Y7+Y8+Y9+Y10
Y5 ~~ Y6+Y7+Y8+Y9+Y10
Y6 ~~ Y7+Y8+Y9+Y10
Y7 ~~ Y8+Y9+Y10
Y8 ~~ Y9+Y10
Y9 ~~ Y10
X1 ~~ X2+X3+X4+X5+X6+X7+X8+X9+X10
X2 ~~ X3+X4+X5+X6+X7+X8+X9+X10
X3 ~~ X4+X5+X6+X7+X8+X9+X10
X4 ~~ X5+X6+X7+X8+X9+X10
X5 ~~ X6+X7+X8+X9+X10
X6 ~~ X7+X8+X9+X10
X7 ~~ X8+X9+X10
X8 ~~ X9+X10
X9 ~~ X10
'
sem(model = myModel, data = SEMdata)
getwd()
datset <- 1
sampsize <- 200
setwd("C:/Users/alex/OneDrive/Documents/GitHub/Dissertation_Projects/Project_2/NelderMead_Code")
### Random seed
set.seed(2435)
### To initialize parameters
source(file = "Model_Meta_Param.R")
source(file = "Model_Matrix_Param.R")
install.packages("pracma")
datset <- 1
sampsize <- 200
setwd("C:/Users/alex/OneDrive/Documents/GitHub/Dissertation_Projects/Project_2/NelderMead_Code")
### Random seed
set.seed(2435)
### To initialize parameters
source(file = "Model_Meta_Param.R")
source(file = "Model_Matrix_Param.R")
datset <- 1
sampsize <- 200
setwd("C:/Users/alex/OneDrive/Documents/GitHub/Dissertation_Projects/Project_2/NelderMead_Code")
### Random seed
set.seed(2435)
### To initialize parameters
library(pracma)
source(file = "Model_Meta_Param.R")
source(file = "Model_Matrix_Param.R")
datset <- 1
sampsize <- 200
setwd("C:/Users/alex/OneDrive/Documents/GitHub/Dissertation_Projects/Project_2/NelderMead_Code")
### Random seed
set.seed(2435)
### To initialize parameters
library(pracma)
library(MASS)
source(file = "Model_Meta_Param.R")
source(file = "Model_Matrix_Param.R")
### To generate simulated data
source(file = "Data_Generation.R")
set.seed(datset)
MyData <- Data_Generation(n = sampsize, Model_Params=Model_Params)
source(file = "Lasso.R")
library(pracma)
library(MASS)
library(r.jive)
library(nloptr)
install.packages("nloptr")
library(pracma)
library(MASS)
library(r.jive)
library(nloptr)
setwd("C:/Users/alex/OneDrive/Documents/GitHub/Dissertation_Projects/Project_2/NelderMead_Code")
datset <- 1
sampsize <- 200
set.seed(2435)
code_dir <- paste0("C:/Users/alex/OneDrive/Documents/GitHub/Dissertation_Projects/Project_2/NelderMead_Code/")
source(file = paste0(code_dir, "Model_Meta_Param.R") )
source(file = paste0(code_dir, "Model_Matrix_Param_Sparse.R") )
code_dir <- paste0("C:/Users/alex/OneDrive/Documents/GitHub/Dissertation_Projects/Project_2/NelderMead_Code/")
source(file = paste0(code_dir, "Model_Meta_Param.R") )
source(file = paste0(code_dir, "Model_Matrix_Param_Sparse.R") )
### To generate simulated data
source(file = paste0(code_dir, "Data_Generation.R") )
set.seed(datset)
MyData <- Data_Generation(n = sampsize, Model_Params=Model_Params)
source(file = paste0(code_dir, "Lasso.R") )
source(file = paste0(code_dir, "X_Inits2.R") )
source(file = paste0(code_dir, "Estep_X.R") )
source(file = paste0(code_dir, "Mstep_X.R") )
source(file = paste0(code_dir, "logLik_X.R") )
source(file = paste0(code_dir, "Convergence_check.R") )
source(file = paste0(code_dir, "BIC_X.R") )
source(file = paste0(code_dir, "EMAlg_XNM.R") )
source(file = paste0(code_dir, "OverallXAlgNM.R") )
NMWrapperX <- function(Xinit, Data, tuningvals){
return(neldermead(tuningvals, EMAlg_X, lower = rep(0, 4), Data = Data, initial_Model_Params = Xinit))
}
Xest <- OverallXAlg(MyData, m_seq = 4, u_seq = list(2, 3))
source(file = paste0(code_dir, "Y_Inits2.R") )
source(file = paste0(code_dir, "Estep_Y.R") )
source(file = paste0(code_dir, "Mstep_Y.R") )
source(file = paste0(code_dir, "logLik_Y.R") )
source(file = paste0(code_dir, "BIC_Y.R") )
source(file = paste0(code_dir, "EMAlg_YNM.R") )
source(file = paste0(code_dir, "OverallYAlgNM.R") )
NMWrapperY <- function(Yinit, Data, Xest, tuningvals){
return(neldermead(tuningvals, EMAlg_Y, lower = rep(0, 4), Data = Data, Xest = Xest, initial_Model_Params = Yinit))
}
source(file = paste0(code_dir, "Y_Inits2.R") )
source(file = paste0(code_dir, "Estep_Y.R") )
source(file = paste0(code_dir, "Mstep_Y.R") )
source(file = paste0(code_dir, "logLik_Y.R") )
source(file = paste0(code_dir, "BIC_Y.R") )
source(file = paste0(code_dir, "EMAlg_YNM.R") )
source(file = paste0(code_dir, "OverallYAlgNM.R") )
Yest <- OverallYAlg(MyData, Xest, j_seq = 4:6, z_seq = list(3, 2))
library(tidyverse)
install.packages("tidyverse")
library(tidyverse)
library(ggplot2)
library(hrbrthemes)
install.packages("hrbrthemes")
library(tidyverse)
library(ggplot2)
library(hrbrthemes)
library(ggpubr)
install.packages("ggpubr")
library(tidyverse)
library(ggplot2)
library(hrbrthemes)
library(ggpubr)
library(grid)
library(networkD3)
install.packages("networkD3")
library(tidyverse)
library(ggplot2)
library(hrbrthemes)
library(ggpubr)
library(grid)
library(networkD3)
# Set Default Chunk Options
knitr::opts_chunk$set(echo = FALSE)
# Define constants
seed_val <- 42
colorblind_palette  <- c("#999999", "#E69F00", "#56B4E9", "#009E73",
"#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# Load source files
set.seed(seed_val)
source("00_aesthetic_utils.R")
library(tidyverse)
library(ggplot2)
library(hrbrthemes)
library(ggpubr)
library(grid)
library(networkD3)
# Set Default Chunk Options
setwd("C:/Users/alex/OneDrive/Documents/GitHub/best-figure-prototyping/code")
# Define constants
seed_val <- 42
colorblind_palette  <- c("#999999", "#E69F00", "#56B4E9", "#009E73",
"#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# Load source files
set.seed(seed_val)
source("00_aesthetic_utils.R")
source("01_gen_fake_data.R")
source("02_plot_predictors.R")
source('03_plot_value_comparisons.R')
source('04_plot_dtr_assignments.R')
source('05_plot_forest_subgroups.R')
pred_summary_df <- FakeDataForPredictorSummary()
#pred_summary_plot <- PlotPredictorSummary(in.data = pred_summary_df)
alt_pred <- PlotPredImportance(in.data = pred_summary_df)
pubr_pred <- PlotPredPubr(in.data = pred_summary_df)
pred_lollipop_plot <- PlotPredictorLollipop(in.data = pred_summary_df)
#ThemePlot(pred_summary_plot)
ThemePlot(pred_summary_plot)
pubr_pred
ThemePlot(alt_pred)
ThemePlot(pred_lollipop_plot)
dtr_assignments <- FakeDataForDTRAssignments()
PlotDTRAssignments(dtr_assignments)
dtr_assignments <- FakeDataForDTRAssignments(stage1_trt_probs = c(0.6, 0.1, 0.2, 0.1),
act_action_probs = c(0.6, 0.1, 0.3),
dulox_action_probs = c(0.1, 0.8, 0.1),
ebem_action_probs = c(0.1, 0.4, 0.5),
esc_action_probs = c(0.2, 0.8, 0))
PlotDTRAssignments(dtr_assignments)
dtr_assignments <- FakeDataForDTRAssignments(stage1_trt_probs = c(0.6, 0, 0, 0.4),
act_action_probs = c(0.6, 0.4, 0),
dulox_action_probs = c(0.1, 0.8, 0.1),
ebem_action_probs = c(0.1, 0.4, 0.5),
esc_action_probs = c(0.5, 0.5, 0))
PlotDTRAssignments(dtr_assignments)
policy_names <- c("Ensemble", "Interpretable", "Personalize\nStage One Only", "Best Single\nTreatment", "As-randomized")
fake_val_data <- FakeDataForValueComparison(policy_names,
point_estimates = c(.65, .6, .475, .4, .3),
ci_half_widths = c(.15, .15, .15, .15, .1))
fake_val_min_comp <- fake_val_data %>% filter(TreatmentPolicy %in% c("Ensemble", "Interpretable","As-randomized"))
val_plot_multi <- PlotValueComparison(in.data = fake_val_data)
val_plot_min <- PlotValueComparison(in.data = fake_val_min_comp)
ThemePlot(val_plot_min)
ThemePlot(val_plot_multi)
dtr_data <- tibble(
subgroup = c("Overall", "Age <=65 yr", "Age > 65", "Years cLBP >5", "Years cLBP <=5",
"Anxiety +", "Anxiety -"), # ... continue for all subgroups
value = c(1, 1.1, 0.6, 0.7, 1.2, 1.3, 0.65),
method = 'Personalized Treatments'
) %>%
mutate(subgroup = factor(subgroup,
levels = rev(c("Overall", subgroup[which(subgroup != 'Overall')]))))
trial_average_data <- tibble(
subgroup = c("Overall", "Age <=65 yr", "Age > 65", "Years cLBP >5", "Years cLBP <=5",
"Anxiety +", "Anxiety -"), # ... continue for all subgroups
value = c(0.85, 0.8, 0.9, 1, 0.72, 1, 0.8),
method = 'Trial Average'
) %>%
mutate(subgroup = factor(subgroup,
levels = rev(c("Overall", subgroup[which(subgroup != 'Overall')]))))
pdat <- bind_rows(dtr_data, trial_average_data)
segments_data <- pdat %>%
pivot_wider(id_cols = subgroup,names_from = method,
values_from = value) %>%
janitor::clean_names() %>%
mutate(
diff = personalized_treatments - trial_average,
color = ifelse(diff > 0, "Positive", "Negative")
)
install.packages("janitor")
library(janitor)
dtr_data <- tibble(
subgroup = c("Overall", "Age <=65 yr", "Age > 65", "Years cLBP >5", "Years cLBP <=5",
"Anxiety +", "Anxiety -"), # ... continue for all subgroups
value = c(1, 1.1, 0.6, 0.7, 1.2, 1.3, 0.65),
method = 'Personalized Treatments'
) %>%
mutate(subgroup = factor(subgroup,
levels = rev(c("Overall", subgroup[which(subgroup != 'Overall')]))))
trial_average_data <- tibble(
subgroup = c("Overall", "Age <=65 yr", "Age > 65", "Years cLBP >5", "Years cLBP <=5",
"Anxiety +", "Anxiety -"), # ... continue for all subgroups
value = c(0.85, 0.8, 0.9, 1, 0.72, 1, 0.8),
method = 'Trial Average'
) %>%
mutate(subgroup = factor(subgroup,
levels = rev(c("Overall", subgroup[which(subgroup != 'Overall')]))))
pdat <- bind_rows(dtr_data, trial_average_data)
segments_data <- pdat %>%
pivot_wider(id_cols = subgroup,names_from = method,
values_from = value) %>%
janitor::clean_names() %>%
mutate(
diff = personalized_treatments - trial_average,
color = ifelse(diff > 0, "Positive", "Negative")
)
PlotSubgroupForest(value_data = pdat, segments_data = segments_data)
ThemePlot(alt_pred)
pred_summary_df <- FakeDataForPredictorSummary()
#pred_summary_plot <- PlotPredictorSummary(in.data = pred_summary_df)
alt_pred <- PlotPredImportance(in.data = pred_summary_df)
pubr_pred <- PlotPredPubr(in.data = pred_summary_df)
pred_lollipop_plot <- PlotPredictorLollipop(in.data = pred_summary_df)
pubr_pred
ThemePlot(alt_pred)
ThemePlot(pred_lollipop_plot)
dtr_assignments <- FakeDataForDTRAssignments()
PlotDTRAssignments(dtr_assignments)
ThemePlot(alt_pred)
PlotDTRAssignments(dtr_assignments)
dtr_assignments <- FakeDataForDTRAssignments(stage1_trt_probs = c(0.6, 0.1, 0.2, 0.1),
act_action_probs = c(0.6, 0.1, 0.3),
dulox_action_probs = c(0.1, 0.8, 0.1),
ebem_action_probs = c(0.1, 0.4, 0.5),
esc_action_probs = c(0.2, 0.8, 0))
PlotDTRAssignments(dtr_assignments)
dtr_assignments <- FakeDataForDTRAssignments(stage1_trt_probs = c(0.6, 0, 0, 0.4),
act_action_probs = c(0.6, 0.4, 0),
dulox_action_probs = c(0.1, 0.8, 0.1),
ebem_action_probs = c(0.1, 0.4, 0.5),
esc_action_probs = c(0.5, 0.5, 0))
PlotDTRAssignments(dtr_assignments)
policy_names <- c("Ensemble", "Interpretable", "Personalize\nStage One Only", "Best Single\nTreatment", "As-randomized")
fake_val_data <- FakeDataForValueComparison(policy_names,
point_estimates = c(.65, .6, .475, .4, .3),
ci_half_widths = c(.15, .15, .15, .15, .1))
fake_val_min_comp <- fake_val_data %>% filter(TreatmentPolicy %in% c("Ensemble", "Interpretable","As-randomized"))
val_plot_multi <- PlotValueComparison(in.data = fake_val_data)
val_plot_min <- PlotValueComparison(in.data = fake_val_min_comp)
ThemePlot(val_plot_min)
ThemePlot(val_plot_multi)
dtr_data <- tibble(
subgroup = c("Overall", "Age <=65 yr", "Age > 65", "Years cLBP >5", "Years cLBP <=5",
"Anxiety +", "Anxiety -"), # ... continue for all subgroups
value = c(1, 1.1, 0.6, 0.7, 1.2, 1.3, 0.65),
method = 'Personalized Treatments'
) %>%
mutate(subgroup = factor(subgroup,
levels = rev(c("Overall", subgroup[which(subgroup != 'Overall')]))))
trial_average_data <- tibble(
subgroup = c("Overall", "Age <=65 yr", "Age > 65", "Years cLBP >5", "Years cLBP <=5",
"Anxiety +", "Anxiety -"), # ... continue for all subgroups
value = c(0.85, 0.8, 0.9, 1, 0.72, 1, 0.8),
method = 'Trial Average'
) %>%
mutate(subgroup = factor(subgroup,
levels = rev(c("Overall", subgroup[which(subgroup != 'Overall')]))))
pdat <- bind_rows(dtr_data, trial_average_data)
segments_data <- pdat %>%
pivot_wider(id_cols = subgroup,names_from = method,
values_from = value) %>%
janitor::clean_names() %>%
mutate(
diff = personalized_treatments - trial_average,
color = ifelse(diff > 0, "Positive", "Negative")
)
PlotSubgroupForest(value_data = pdat, segments_data = segments_data)
## AlexProject1_CodeTesting_v01
### Random seed
library(pracma)
library(MASS)
library(r.jive)
library(nloptr)
setwd("C:/Users/alex/OneDrive/Documents/GitHub/Dissertation_Projects/Project_2/NelderMead_Code")
datset <- 1
sampsize <- 200
set.seed(2435)
### To initialize parameters
code_dir <- paste0("C:/Users/alex/OneDrive/Documents/GitHub/Dissertation_Projects/Project_2/NelderMead_Code/")
source(file = paste0(code_dir, "Model_Meta_Param.R") )
source(file = paste0(code_dir, "Model_Matrix_Param_Sparse.R") )
### To generate simulated data
source(file = paste0(code_dir, "Data_Generation.R") )
set.seed(datset)
MyData <- Data_Generation(n = sampsize, Model_Params=Model_Params)
### To get estimates for the X part ...
source(file = paste0(code_dir, "Lasso.R") )
source(file = paste0(code_dir, "X_Inits2.R") )
source(file = paste0(code_dir, "Estep_X.R") )
source(file = paste0(code_dir, "Mstep_X.R") )
source(file = paste0(code_dir, "logLik_X.R") )
source(file = paste0(code_dir, "Convergence_check.R") )
source(file = paste0(code_dir, "BIC_X.R") )
source(file = paste0(code_dir, "EMAlg_XNM.R") )
source(file = paste0(code_dir, "OverallXAlgNM.R") )
# Singular_ErrorX <- function(tuningList, Data, initial_Model_Params, weights){
#   return(tryCatch(EMAlg_X(tuningList, Data, initial_Model_Params, weights), error = function(e) NULL))
# }
#
# Singular_ErrorX2 <- function(initial_Model_Params, Data, tuningpA1, tuningpB1, tuningpA2, tuningpB2){
#   return(tryCatch(EMAlg_X(initial_Model_Params, Data, tuningpA1, tuningpB1, tuningpA2, tuningpB2), error = function(e) NULL))
# }
NMWrapperX <- function(Xinit, Data, tuningvals){
return(neldermead(tuningvals, EMAlg_X, lower = rep(0, 4), Data = Data, initial_Model_Params = Xinit))
}
Xest <- OverallXAlg(MyData, m_seq = 4, u_seq = list(2, 3))
source(file = paste0(code_dir, "Y_Inits2.R") )
source(file = paste0(code_dir, "Estep_Y.R") )
source(file = paste0(code_dir, "Mstep_Y.R") )
source(file = paste0(code_dir, "logLik_Y.R") )
source(file = paste0(code_dir, "BIC_Y.R") )
source(file = paste0(code_dir, "EMAlg_YNM.R") )
source(file = paste0(code_dir, "OverallYAlgNM.R") )
### To fix X part at truth when estimating Y part
### COMMENT OUT THIS CHUNK WHEN ESTIMATING X INSTEAD OF FIXING AT TRUTH ###
# Xest <- list()
# X_Param <- Model_Params[c(1:4, 15:17, 21:22)]
# Xest$X_final_pars <- X_Param
# Xest$m_opt <- 4
# Xest$u1_opt <- 2
# Xest$u2_opt <- 3
# Xest$X_log.Lik <- 2
# Xest$diffList <- NA
# Xest$X_BIC <- 432
# Xest$tuningpA1 <- 0
# Xest$tuningpB1 <- 0
# Xest$tuningpA2 <- 0
# Xest$tuningpB2 <- 0
#
# Xest$X_time_diff <- 0
# Singular_ErrorY2 <- function(initial_Model_Params, Data, Xest, tuningpG1, tuningpD1, tuningpG2, tuningpD2){
#   return(tryCatch(EMAlg_Y(initial_Model_Params, Data, Xest, tuningpG1, tuningpD1, tuningpG2, tuningpD2), error = function(e) NULL))
# }
NMWrapperY <- function(Yinit, Data, Xest, tuningvals){
return(neldermead(tuningvals, EMAlg_Y, lower = rep(0, 4), Data = Data, Xest = Xest, initial_Model_Params = Yinit))
}
Yest <- OverallYAlg(MyData, Xest, j_seq = 5, z_seq = list(3, 2))
